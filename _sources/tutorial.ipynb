{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Parallelization Techniques\n",
    "\n",
    "The goals of this tutorial:\n",
    "- Basic concepts of parallelization\n",
    "- vectorization\n",
    "- threads/processes/GIL\n",
    "- MPI\n",
    "- GPU/TPUs\n",
    "- High-level python parallelization techniques\n",
    "\n",
    "We'll go over some details (~10 min + QA) and then break into groups of 2-3 to work on some exercises.\n",
    "\n",
    "\n",
    "The exercises:\n",
    "|              |                                    |\n",
    "|:-------------|:----------------------------------:|\n",
    "| π-estimation |  ![](excercises/pi_estimation.gif)  |\n",
    "| N-Body sim   | ![](excercises/out_nb_np/orbit.gif) |\n",
    "| Fractals     | ![]() |\n",
    "\n",
    "## Overview\n",
    "\n",
    "There are several ways to increase the number of computations per second. Some include:\n",
    "1. Increasing the number of computations per clock cycle:\n",
    "    - by adding more transistors to a single CPU\n",
    "    - by increasing the clock speed of a single CPU\n",
    "2. Increasing the number of 'workers' crunching computations:\n",
    "    - by adding more 'cores' to a single machine\n",
    "    - by adding more machines to a network\n",
    "    - by using specialized hardware to do the math (e.g., GPUs, TPUs, FPGAs, etc.)\n",
    "\n",
    "\n",
    "The first approach is called **serial** computing, and the second approach is called **parallel** computing.\n",
    "\n",
    "Unfortunately, the first approach has hit a wall. See the figures from the [Standford VLSI Group's CPU DB](http://cpudb.stanford.edu/visualize/clock_frequency).\n",
    "|Features on a chip | Clock speed |\n",
    "|:------------------|:-----------:|\n",
    "| ![](static/feature_size.png)         | ![](static/clock_cycle.png)       |\n",
    "\n",
    "We're unlikely to make drastic improvements in either of these in the near future, due to inherent physical\n",
    "limitations on the construction of chips and circuit boards.\n",
    "**Parallel computing is a way forward.**\n",
    "\n",
    "\n",
    "\n",
    "The pioneer of multiprocessing, and \"Father of supercomputing\", [Seymour Cray](https://www.britannica.com/biography/Seymour-R-Cray), once said:\n",
    "> If you were plowing a field, which would you rather use? Two strong oxen or 1024 chickens?”\n",
    ">\n",
    "> - Seymour Cray,\n",
    "\n",
    "![](static/chick_vs_ox.png)\n",
    "\n",
    "Cray considered this an obvious question, as to him, it is absurd to plough a field with chickens.\n",
    "He thought it would be absurd to use several processors to crunch\n",
    "computations in parallel, in place of one fast processor to crunch computations sequentially.\n",
    "By the early 2000s, views began to shift...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Flynn's taxonomy and \"types\" of parallelization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### The remainder of this tutorial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```note\n",
    "We will focus on the SIMD (Single Instruction Multiple Data) type of parallelization.\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Very relavent video of [several thousand chickens fighting a few T-rexes](https://www.youtube.com/watch?v=Tc_JWE_ypEk)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import process_time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "def fn(x):\n",
    "    return x + x * x + x * x * x\n",
    "\n",
    "\n",
    "def runtime_loops(x):\n",
    "    _ = np.empty_like(x)\n",
    "    t0 = process_time()\n",
    "    for i in range(len(x)):\n",
    "        _[i] = fn(x[i])\n",
    "    return process_time() - t0\n",
    "\n",
    "\n",
    "def runtime_np_vectorized(x):\n",
    "    t0 = process_time()\n",
    "    _ = fn(x)\n",
    "    return process_time() - t0\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    # Check the current device\n",
    "    print(f\"CuPy platform: {cp.cuda.Device()}\")\n",
    "    CUPY_INSTALLED = True\n",
    "except ImportError:\n",
    "    CUPY_INSTALLED = False\n",
    "    warnings.warn(\"Cupy not installed\")\n",
    "\n",
    "try:\n",
    "    import jax.numpy as jnp\n",
    "    from jax import jit\n",
    "    from jax.lib import xla_bridge\n",
    "    print(f\"JAX platform: {xla_bridge.get_backend().platform}\")\n",
    "    JAX_INSTALLED = True\n",
    "except ImportError:\n",
    "    JAX_INSTALLED = False\n",
    "    warnings.warn(\"Jax not installed\")\n",
    "\n",
    "\n",
    "def runtime_multiprocessing(x):\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    t0 = process_time()\n",
    "    _ = pool.map(fn, x)\n",
    "    return process_time() - t0\n",
    "\n",
    "\n",
    "def runtime_multithreading(x):\n",
    "    pool = mp.pool.ThreadPool(mp.cpu_count())\n",
    "    t0 = process_time()\n",
    "    _ = pool.map(fn, x)\n",
    "    return process_time() - t0\n",
    "\n",
    "if JAX_INSTALLED:\n",
    "  jax_fn = jit(fn)\n",
    "\n",
    "def runtime_jax(x):\n",
    "    if not JAX_INSTALLED:\n",
    "        return np.nan\n",
    "    x = jnp.array(x)\n",
    "    t0 = process_time()\n",
    "    _ = jax_fn(x).block_until_ready()\n",
    "    return process_time() - t0\n",
    "\n",
    "\n",
    "def runtime_cupy(x):\n",
    "    if not CUPY_INSTALLED:\n",
    "        return np.nan\n",
    "    x = cp.array(x)\n",
    "    t0 = process_time()\n",
    "    _ = fn(x).get()\n",
    "    return process_time() - t0\n",
    "\n",
    "\n",
    "RUNTIME_FUNCS = dict(\n",
    "    loops=runtime_loops,\n",
    "    np_vectorized=runtime_np_vectorized,\n",
    "    multiprocessing=runtime_multiprocessing,\n",
    "    multithreading=runtime_multithreading,\n",
    "    jax=runtime_jax,\n",
    "    cupy=runtime_cupy,\n",
    ")\n",
    "\n",
    "\n",
    "def collect_runtime_data(n_vals, n_trials=5):\n",
    "    runtimes = {k: [] for k in RUNTIME_FUNCS.keys()}\n",
    "    for i, n in tqdm(enumerate(n_vals), total=len(n_vals)):\n",
    "        x = np.random.randn(n, n).astype(dtype='float32')\n",
    "        for k, fn in RUNTIME_FUNCS.items():\n",
    "            trials = np.empty(n_trials)\n",
    "            for j in range(n_trials):\n",
    "                trials[j] = fn(x)\n",
    "            if n_trials > 1:\n",
    "                trials = trials[trials.argsort()[:-1]]\n",
    "            runtimes[k].append(np.quantile(trials, [0.05, 0.5, 0.95]))\n",
    "\n",
    "    for k in RUNTIME_FUNCS.keys():\n",
    "      runtimes[k] = np.array(runtimes[k])\n",
    "\n",
    "    return runtimes\n",
    "\n",
    "\n",
    "def plot_runtimes(n_vals, runtimes):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for i, (k, v) in enumerate(runtimes.items()):\n",
    "        ax.plot(n_vals, v[:,1], label=k, color=f'C{i}')\n",
    "        ax.fill_between(n_vals, v[:,0], v[:,2], alpha=0.2, color=f'C{i}')\n",
    "    ax.set_xlabel('Array Size')\n",
    "    ax.set_ylabel('Runtime (s)')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(min(n_vals),max(n_vals))\n",
    "    ax.legend(fontsize=15, frameon=False)\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "n_vals = np.geomspace(1e2, 1e3, 10).astype(int)\n",
    "runtimes = collect_runtime_data(n_vals)\n",
    "plot_runtimes(n_vals, runtimes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DEMO 1: using `vectorization`\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "n = 10000\n",
    "# Generate n random numbers between 0 - 1\n",
    "theta = np.random.rand(n)\n",
    "#Generate n random integers between 0 - 100\n",
    "x = np.random.randint(0, 100, n)\n",
    "\n",
    "\n",
    "# Unvectorized\n",
    "def unvectorized(n, theta, x):\n",
    "    prediction = 0.0\n",
    "\n",
    "    for j in range(n):\n",
    "        prediction = prediction + theta[j] * x[j]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# Vectorized\n",
    "def vectorized(theta, x):\n",
    "    prediction = 0.0\n",
    "\n",
    "    prediction = np.dot(theta.transpose(), x)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "#Comparing Performance\n",
    "% timeit unvectorized(n, theta, x)\n",
    "% timeit vectorized(theta, x)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DEMO 2: Parallelization with `multithreading`"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DEMO 3: Parallelization with `multiprocessing`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DEMO 4: Parallelization with `mpi`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DEMO 5: Parallel \"jobs\" on a cluster\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FAQ\n",
    "\n",
    "### Do I need to parallelize my code?\n",
    "\n",
    "### Difference between `multiprocessing` and `multithreading`?\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
